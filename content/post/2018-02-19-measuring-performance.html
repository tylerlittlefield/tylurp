---
title: Measuring performance
author: ~
date: '2018-02-13'
slug: measuring-performance
categories: ['r']
tags: []
---



<div class="figure">
<img src="https://raw.githubusercontent.com/tyluRp/tylurp/master/figure/long_to_wide_density.png" />

</div>
<p>With any data science project there may be times where performance is a concern. This might be a result of the datas size or a lack of resources. In any case, we can use <code>microbenchmark</code> to measure the performance of specific functions.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>I discovered this package on Stack Overflow as someone measured the performance of their answer among others. Hadley Wickham also writes about <code>microbenchmark</code> in his <a href="https://adv-r.hadley.nz/performance.html">Advanced R</a> book. As of late, what I have found really useful is an <a href="https://stackoverflow.com/a/48708439/7362046">answer on Stack Overflow by Jaap</a> where he measures the performance of many alternative solutions for a specific problem in this case, finding the sequence of numbers in a vector.</p>
<p>For this post, let’s consider the long to wide problem. We want to take a long dataset and make it wide. Furthermore, we want to insure that the solution to this problem is faster than the alternatives we can come up with. Off the top of my head, I can think of 5 ways to do this:</p>
<ol style="list-style-type: decimal">
<li><code>spread</code> from the <code>tidyr</code> package</li>
<li><code>dcast</code> from the <code>reshape2</code> package (superseeded by <code>tidyr</code>)</li>
<li><code>reshape</code> from the <code>stats</code> package</li>
<li><code>aggregate</code> from the <code>stats</code> package</li>
<li><code>dcast</code> from the <code>data.table</code> package</li>
</ol>
<p>Now that we’ve gathered a few solutions to this problem, we can create a reproducible dataset. This way others can use it. Additionally, I want to make it easy to increase the size of the data:</p>
<pre class="r"><code>library(dplyr)
library(tidyr)

# Adjust n_obs to increase size of dataset
n_obs &lt;- 1e2
n_date &lt;- n_obs - 1

# Create dataset
stocks &lt;- data.frame(
  time = as.Date(&#39;2009-01-01&#39;) + 0:n_date,
  X = rnorm(n_obs, 0, 1),
  Y = rnorm(n_obs, 0, 2),
  Z = rnorm(n_obs, 0, 4)
)

# Gather wide to long
stocksm &lt;- stocks %&gt;% gather(stock, price, -time)

# Create data.table object for benchmarking purposes
stocksm_dt &lt;- data.table::as.data.table(stocksm)</code></pre>
<p>The result looks like:</p>
<pre class="r"><code>as_tibble(stocksm)</code></pre>
<pre><code>## # A tibble: 300 x 3
##    time       stock   price
##    &lt;date&gt;     &lt;chr&gt;   &lt;dbl&gt;
##  1 2009-01-01 X     -1.17  
##  2 2009-01-02 X      0.733 
##  3 2009-01-03 X      0.333 
##  4 2009-01-04 X      0.371 
##  5 2009-01-05 X      0.956 
##  6 2009-01-06 X     -0.356 
##  7 2009-01-07 X     -1.75  
##  8 2009-01-08 X      0.114 
##  9 2009-01-09 X      0.962 
## 10 2009-01-10 X     -0.0254
## # ... with 290 more rows</code></pre>
<p>We have three variables, <code>time</code>, <code>stock</code>, and <code>price</code> and we want to spread <code>stock</code> so that we can look at the <code>price</code> for each <code>stock</code> at a given <code>time</code>.</p>
<p>We will measure the performance of the following functions:</p>
<pre class="r"><code>tidyr::spread(stocksm, stock, price)
reshape2::dcast(stocksm, time ~ stock)
stats::aggregate(price ~ time, stocksm, I)
stats::reshape(stocksm_dt, idvar = &quot;time&quot;, timevar = &quot;stock&quot;, direction = &quot;wide&quot;)
data.table::dcast(stocksm_dt, time ~ stock)
data.table::dcast(stocksm_dt, time ~ stock, value.var = &quot;time&quot;) # enhanced</code></pre>
<p>All of these (more or less) return:</p>
<pre class="r"><code>stocksm %&gt;% 
  spread(stock, price) %&gt;% 
  head()</code></pre>
<pre><code>##         time          X          Y         Z
## 1 2009-01-01 -1.1719574 -0.3167503 -1.917618
## 2 2009-01-02  0.7327585  0.4155328  1.080215
## 3 2009-01-03  0.3330596  4.0449968 -6.241746
## 4 2009-01-04  0.3708493 -1.8551497  9.633452
## 5 2009-01-05  0.9559459  3.2414339  6.026590
## 6 2009-01-06 -0.3564109  1.6864852  7.600460</code></pre>
<p><strong>Update: See <a href="https://tylurp.rbind.io/2018/04/03/equality-matrix-a-useful-idea-for-benchmarking/">this post</a> for a concise method of testing equal outputs for numerous possible solutions at once</strong></p>
<p>And the <em>more or less</em> part is important and is one of the things I learned from Jaaps answer on Stack Overflow. When measuring performance we can check to see if the output is equal among all possible solutions. We can do this with the <code>all.equal</code> function, i.e. <code>all.equal(x, y)</code> where <code>x</code> is our target object and <code>y</code> is our current object to be used for testing ‘near equality’ between the two:</p>
<pre class="r"><code>all.equal(
  tidyr::spread(stocksm, stock, price),
  reshape2::dcast(stocksm, time ~ stock)
)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>We can see that <code>reshape2</code> and <code>tidyr</code> return the same output. This isn’t too suprising as <code>tidyr</code> superseeded <code>reshape2</code> and is authored by the same person. However, if we test the outputs of the other solutions we’ll see that the output is not the same:</p>
<pre class="r"><code>isTRUE(all.equal(
  tidyr::spread(stocksm, stock, price),
  stats::aggregate(price ~ time, stocksm, I)
))</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p>The differences between the four solutions has to do with the structure of the output. Some are data frames, some are data tables and others are matrices. Remove the <code>isTRUE</code> surrounding the <code>all.equal</code> call in order to see these differences. If we treat each operation as a matrix the only difference between each of the outputs is the <code>dimnames</code> or the names of the dimensions/variables in each R object.</p>
<pre class="r"><code>all.equal(
  tidyr::spread(stocksm, stock, price) %&gt;% as.matrix(),
  stats::aggregate(price ~ time, stocksm, I) %&gt;% as.matrix()
)</code></pre>
<pre><code>## [1] &quot;Attributes: &lt; Component \&quot;dimnames\&quot;: Component 2: 3 string mismatches &gt;&quot;
## [2] &quot;200 string mismatches&quot;</code></pre>
<p>This is due to the functions naming convention as each function names the resulting spread differently. Since we are only concerned with converting a long dataset to wide, let’s not worry about the underlying structure and proceed to measure the performance of all methods.</p>
<p>We can create the functions for running the benchmarks and keeping the <code>microbenchmark</code> call a little cleaner:</p>
<pre class="r"><code>tidyr_spread &lt;- function(dat) {
  tidyr::spread(dat, stock, price)
}

reshape_dcast &lt;- function(dat) {
  reshape2::dcast(dat, time ~ stock)
}

stats_aggregate &lt;- function(dat) {
  stats::aggregate(price ~ time, dat, I)
}

stats_reshape &lt;- function(dat) {
  stats::reshape(dat, idvar = &quot;time&quot;, timevar = &quot;stock&quot;, direction = &quot;wide&quot;)
}

data.table_dcast &lt;- function(dat) {
  data.table::dcast(dat, time ~ stock)
}

data.table_dcast_enhanced &lt;- function(dat) {
  data.table::dcast(dat, time ~ stock, value.var = &quot;time&quot;)
}</code></pre>
<p>Finally, we can benchmark!</p>
<pre class="r"><code>bms &lt;- microbenchmark::microbenchmark(
  tidyr_spread = tidyr_spread(stocksm),
  reshape_dcast = reshape_dcast(stocksm),
  stats_aggregate = stats_aggregate(stocksm),
  stats_reshape = stats_reshape(stocksm),
  data.table_dcast = data.table_dcast(stocksm_dt),
  data.table_dcast_enhanced = data.table_dcast_enhanced(stocksm_dt),
  times = 100
)</code></pre>
<p>The results are:</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/tyluRp/tylurp/master/figure/benchmark_long_to_wide_average.png" />

</div>
<ul>
<li><p><code>spread</code> from <code>tidyr</code> is great for exploratory data analysis on small datasets or small samples of large datasets.</p></li>
<li><p><code>dcast</code> from <code>data.table</code> is clearly faster once the data gets larger and should be used for spreading big data.</p></li>
<li><p><code>reshape</code> and <code>aggregate</code> from the <code>stats</code> package perform the worst.</p></li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><code>microbenchmark</code> is an R package designed to make benchmarking easy.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
